{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V8Z48rb2qQP"
   },
   "source": [
    "## Importing Libs, Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPZP1fiOqG57"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfMqjECppl5U"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gm0E57PqG8o"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1iqFKU9zAQt"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "Chi5aIMLqG-I",
    "outputId": "f3f98237-52c6-44e1-82fb-eb669da52e30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  ...  class                                              tweet\n",
       "0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3EPjCtxqrY6"
   },
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vezKk-ZGqHBe"
   },
   "outputs": [],
   "source": [
    "text_length = []\n",
    "for i in range(len(df)):\n",
    "    text_length.append(len(df['tweet'][i]))\n",
    "df['text length'] = text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGQNi6QXzhdl"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REBm5I8ny_oz"
   },
   "outputs": [],
   "source": [
    "def normalize_opinion(text):\n",
    "    # import the english stop words list from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Instantiate stemming class\n",
    "    stemmer = PorterStemmer() \n",
    "    \n",
    "    filtered_text = []\n",
    "\n",
    "    # Tokenization, lowercasing, removing stop words and punctuation and stemming\n",
    "    filtered_text = [stemmer.stem(w.lower()) for w in nltk.word_tokenize(text) if \n",
    "                         w not in string.punctuation and\n",
    "                         w.lower() not in stop_words]   \n",
    "    \n",
    "    # Return the the list of tokens converted into a string    \n",
    "    return  ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hysh0xU9zLG-"
   },
   "outputs": [],
   "source": [
    "df['tweet2'] = df['tweet']  ## Keeping original tweet encase needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5DycFFczLMn"
   },
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: normalize_opinion(x)) # Clean using nltk stopwords, tokenizing, lowercasing, punctuation\n",
    "\n",
    "## might be tokenizing twice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "QZGHOuJEzLPk",
    "outputId": "d7d9bcae-d5ea-47e3-bb31-009037416873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text length</th>\n",
       "      <th>tweet2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>rt mayasolov woman n't complain clean hous amp...</td>\n",
       "      <td>140</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  ...                                             tweet2\n",
       "0      2  ...  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "\n",
       "[1 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64FMQzHv2Tg_"
   },
   "source": [
    "##  Getting Ready to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e28meXZcrbi1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['class'], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDLDPmcYsnTj",
    "outputId": "5a2f5218-26b8-4abc-9d04-c9de0eef5fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8426     charli jacob got confus ice bucket challeng in...\n",
       "3698     juanndacut sharea40ounc playin pussi hole bing...\n",
       "10054    tell mcgirt music ai n't enough.y got ta non m...\n",
       "3451     ihatestevens ai n't show bout dem color diamon...\n",
       "18673    rt blessedarti y'all claim want good amp loyal...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxzVDSjvrbnR"
   },
   "outputs": [],
   "source": [
    "len_vec = [len(elem) for elem in X_train] #[len(elem) for elem in x_test] + [len(elem) for elem in x_val] \n",
    "max_len = 200\n",
    "num_words = 100000\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Fit the tokenizer on the training data\n",
    "t = Tokenizer(num_words=num_words,  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h50DHMPYusEb",
    "outputId": "e6a8ea2d-0b1a-43d0-8fc7-7114e4fab78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  98 3098   18 ...    0    0    0]\n",
      " [3099 4475  898 ...    0    0    0]\n",
      " [  75 8849  420 ...    0    0    0]\n",
      " ...\n",
      " [ 443  644  429 ...    0    0    0]\n",
      " [   2 8703  227 ...    0    0    0]\n",
      " [   1  105   21 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "## CONVERT TRAIN INTO SEQUENCES FOR NN\n",
    "X_train = t.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0JwwrrA2f4r"
   },
   "source": [
    "## Building Neural Net & Begin Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7ypTMzarbts",
    "outputId": "25691b25-1aec-49e9-89d8-1d353e99c263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 16)           1600000   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200, 64)           1088      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200, 16)           1040      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 9603      \n",
      "=================================================================\n",
      "Total params: 1,611,731\n",
      "Trainable params: 1,611,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 16\n",
    "n_classes = 3\n",
    "epochs = 20\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.6))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9VGFQIiusGb",
    "outputId": "8920e9f6-8e8f-4dd6-9b5e-6ca4acc15568",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.6132 - accuracy: 0.7865\n",
      "Epoch 2/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.3352 - accuracy: 0.9008\n",
      "Epoch 3/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.2788 - accuracy: 0.9141\n",
      "Epoch 4/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.2309 - accuracy: 0.9288\n",
      "Epoch 5/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.2032 - accuracy: 0.9311\n",
      "Epoch 6/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1862 - accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "543/543 [==============================] - 13s 25ms/step - loss: 0.1651 - accuracy: 0.9438\n",
      "Epoch 8/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1616 - accuracy: 0.9470\n",
      "Epoch 9/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1505 - accuracy: 0.9468\n",
      "Epoch 10/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1331 - accuracy: 0.9535\n",
      "Epoch 11/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1298 - accuracy: 0.9546\n",
      "Epoch 12/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.1214 - accuracy: 0.9571\n",
      "Epoch 13/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.1114 - accuracy: 0.9612\n",
      "Epoch 14/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.1147 - accuracy: 0.9603\n",
      "Epoch 15/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.1078 - accuracy: 0.9637\n",
      "Epoch 16/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.0905 - accuracy: 0.9691\n",
      "Epoch 17/20\n",
      "543/543 [==============================] - 14s 25ms/step - loss: 0.0958 - accuracy: 0.9650\n",
      "Epoch 18/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.0924 - accuracy: 0.9708\n",
      "Epoch 19/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.0893 - accuracy: 0.9688\n",
      "Epoch 20/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.0841 - accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00dbe96550>"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, np.array(y_train), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "RPM_CaM8usIa",
    "outputId": "069d4c1e-475d-4e86-8e63-99d6504710dd"
   },
   "outputs": [],
   "source": [
    "X_test = t.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHNhRcYA2nAp"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scJy48jausLw",
    "outputId": "4a686b8b-e0fe-479b-8f51-9e1b857f04ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 1s 4ms/step - loss: 1.0907 - accuracy: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0907082557678223, 0.8407531976699829]"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ggf5URMRwxmB",
    "outputId": "9cfe8688-1b6c-4b12-97ad-46fabb4d01f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.22       427\n",
      "           1       0.86      0.96      0.91      5747\n",
      "           2       0.79      0.55      0.65      1261\n",
      "\n",
      "    accuracy                           0.84      7435\n",
      "   macro avg       0.68      0.55      0.59      7435\n",
      "weighted avg       0.82      0.84      0.82      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##CLASSIFICATION REPORT##\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_toxic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
